<h1>Chapter 08: Linear Time Series Models</h1>

<p>This chapter covers:
- How to use time series analysis to diagnose diagnostic statistics that inform the modeling process
- How to estimate and diagnose autoregressive and moving-average time series models
- How to build Autoregressive Conditional Heteroskedasticity (ARCH) models to predict volatility
- How to build vector autoregressive models
- How to use cointegration for a pairs trading strategy</p>

<h2>Analytical tools for diagnostics and feature extraction</h2>

<p>Most of the examples in this chapter use data provided by the Federal Reserve that you can access using the pandas datareader that we introduced in <a href="../02_market_and_fundamental_data">Chapter 2, Market and Fundamental Data</a>. </p>

<p>The code examples for this section are available in the notebook <a href="01_stationarity_and_arima.ipynb"></a>.</p>

<h3>How to decompose time series patterns</h3>

<p>Time series data typically contains a mix of various patterns that can be decomposed into several components, each representing an underlying pattern category. In particular, time series often consist of the systematic components trend, seasonality and cycles, and unsystematic noise. These components can be combined in an additive, linear model, in particular when fluctuations do not depend on the level of the series, or in a non-linear, multiplicative model. </p>

<ul>
<li><code>pandas</code> Time Series and Date functionality <a href="https://pandas.pydata.org/pandas-docs/stable/timeseries.html">docs</a></li>
<li><a href="https://otexts.org/fpp2/decomposition.html">Forecasting - Principles &amp; Practice, Hyndman, R. and Athanasopoulos, G., ch.6 'Time Series Decomposition'</a></li>
</ul>

<h3>How to compute rolling window statistics</h3>

<p>The pandas library includes very flexible functionality to define various window types, including rolling, exponentially weighted and expanding windows.</p>

<ul>
<li><code>pandas</code> window function <a href="https://pandas.pydata.org/pandas-docs/stable/computation.html#window-functions">docs</a></li>
</ul>

<h3>How to measure autocorrelation</h3>

<p>Autocorrelation (also called serial correlation) adapts the concept of correlation to the time series context: just as the correlation coefficient measures the strength of a linear relationship between two variables, the autocorrelation coefficient measures the extent of a linear relationship between time series values separated by a given lag.</p>

<p>We present the following tools to measure autorcorrelation:
- autocorrelation function (ACF)
- partial autocorrelation function (PACF)
- correlogram as a plot of ACF or PACF against the number of lags.</p>

<h3>How to diagnose and achieve stationarity</h3>

<p>The statistical properties, such as the mean, variance, or autocorrelation, of a stationary time series are independent of the period, that is, they don't change over time. Hence, stationarity implies that a time series does not have a trend or seasonal effects and that descriptive statistics, such as the mean or the standard deviation, when computed for different rolling windows, are constant or do not change much over time.</p>

<h3>How to apply time series transformations</h3>

<p>To satisfy the stationarity assumption of linear time series models, we need to transform the original time series, often in several steps. Common transformations include the application of the (natural) logarithm to convert an exponential growth pattern into a linear trend and stabilize the variance, or differencing.</p>

<h3>How to diagnose and address unit roots</h3>

<p>Unit roots pose a particular problem for determining the transformation that will render a time series stationary. In practice, time series of interest rates or asset prices are often not stationary, for example, because there does not exist a price level to which the series reverts. The most prominent example of a non-stationary series is the random walk.</p>

<p>The defining characteristic of a unit-root non-stationary series is long memory: since current values are the sum of past disturbances, large innovations persist for much longer than for a mean-reverting, stationary series. Identifying the correct transformation, and in particular, the appropriate number and lags for differencing is not always clear-cut. We present a few heuristics to guide the process.</p>

<p>Statistical unit root tests are a common way to determine objectively whether (additional) differencing is necessary. These are statistical hypothesis tests of stationarity that are designed to determine whether differencing is required.</p>

<h2>Univariate Time Series Models</h2>

<p>Univariate time series models relate the value of the time series at the point in time of interest to a linear combination of lagged values of the series and possibly past disturbance terms.</p>

<p>While exponential smoothing models are based on a description of the trend and seasonality in the data, ARIMA models aim to describe the autocorrelations in the data. ARIMA(p, d, q) models require stationarity and leverage two building blocks:
- Autoregressive (AR) terms consisting of p-lagged values of the time series
- Moving average (MA) terms that contain q-lagged disturbances</p>

<ul>
<li><p><a href="https://www.wiley.com/en-us/Analysis+of+Financial+Time+Series%2C+3rd+Edition-p-9780470414354">Analysis of Financial Time Series, 3rd Edition, Ruey S. Tsay</a></p></li>
<li><p><a href="https://www.wiley.com/en-us/Quantitative+Equity+Investing%3A+Techniques+and+Strategies-p-9780470262474">Quantitative Equity Investing: Techniques and Strategies, Frank J. Fabozzi, Sergio M. Focardi, Petter N. Kolm</a></p></li>
<li><p><code>statsmodels</code> Time Series Analysis <a href="https://www.statsmodels.org/dev/tsa.html">docs</a></p></li>
</ul>

<h3>How to build autoregressive models</h3>

<p>An AR model of order p aims to capture the linear dependence between time series values at different lags. It closely resembles a multiple linear regression on lagged values of the outcome.</p>

<h3>How to build moving average models</h3>

<p>An MA model of order q uses q past disturbances rather than lagged values of the time series in a regression-like model. Since we do not observe the white-noise disturbance values, MA(q) is not a regression model like the ones we have seen so far. Rather than using least squares, MA(q) models are estimated using maximum likelihood (MLE).</p>

<h3>How to build ARIMA models and extensions</h3>

<p>Autoregressive integrated moving-average ARIMA(p, d, q) models combine AR(p) and MA(q) processes to leverage the complementarity of these building blocks and simplify model development by using a more compact form and reducing the number of parameters, in turn reducing the risk of overfitting.</p>

<ul>
<li>statsmodels State-Space Models <a href="https://www.statsmodels.org/dev/statespace.html">docs</a></li>
</ul>

<h3>How to forecast macro fundamentals</h3>

<p>We will build a SARIMAX model for monthly data on an industrial production time series for the 1988-2017 period. See notebook <a href="01_stationarity_and_arima.ipynb">stationarity<em>and</em>arima</a> for implementation details.</p>

<h3>How to use time series models to forecast volatility</h3>

<p>A particularly important area of application for univariate time series models is the prediction of volatility. The volatility of financial time series is usually not constant over time but changes, with bouts of volatility clustering together. Changes in variance create challenges for time series forecasting using the classical ARIMA models.</p>

<ul>
<li>NYU Stern <a href="https://vlab.stern.nyu.edu/">VLAB</a></li>
</ul>

<h3>How to build a volatility-forecasting model</h3>

<p>The development of a volatility model for an asset-return series consists of four steps:
1. Build an ARMA time series model for the financial time series based on the serial dependence revealed by the ACF and PACF.
2. Test the residuals of the model for ARCH/GARCH effects, again relying on the ACF and PACF for the series of the squared residual.
3. Specify a volatility model if serial correlation effects are significant, and jointly estimate the mean and volatility equations.
4. Check the fitted model carefully and refine it if necessary.</p>

<p>The notebook <a href="02_arch_garch_models.ipynb">arch<em>garch</em>models</a> demonstrates the usage of the ARCH library to estimate time series models for volatility foreccasting with NASDAQ data.  </p>

<ul>
<li>ARCH Library <a href="http://nbviewer.jupyter.org/github/bashtage/arch/blob/master/examples/univariate_volatility_modeling.ipynb">examples</a></li>
</ul>

<h2>Multivariate Time Series Models</h2>

<p>Multivariate time series models are designed to capture the dynamic of multiple time series simultaneously and leverage dependencies across these series for more reliable predictions.</p>

<ul>
<li><a href="https://www.springer.com/us/book/9783540401728">New Introduction to Multiple Time Series Analysis, Lütkepohl, Helmut, Springer, 2005</a></li>
</ul>

<h3>The vector autoregressive (VAR) model</h3>

<ul>
<li><p><code>statsmodels</code> Vector Autoregression <a href="https://www.statsmodels.org/dev/vector_ar.html">docs</a></p></li>
<li><p><a href="https://conference.scipy.org/proceedings/scipy2011/pdfs/statsmodels.pdf">Time Series Analysis in Python with statsmodels</a>, Wes McKinney, Josef Perktold, Skipper Seabold, SciPY Conference 2011</p></li>
</ul>

<h3>How to use the VAR model for macro fundamentals forecasts</h3>

<p>The notebook <a href="03_vector_autoregressive_model.ipynb">vector<em>autoregressive</em>model</a> demonstrates how to use <code>statsmodels</code> to estimate a VAR model for macro fundamentals time series.</p>

<h3>Cointegration – time series with a common trend</h3>

<p>The concept of an integrated multivariate series is complicated by the fact that all the component series of the process may be individually integrated but the process is not jointly integrated in the sense that one or more linear combinations of the series exist that produce a new stationary series.</p>

<p>In other words, a combination of two co-integrated series has a stable mean to which this linear combination reverts. A multivariate series with this characteristic is said to be co-integrated. This also applies when the individual series are integrated of a higher order and the linear combination reduces the overall order of integration. </p>

<p>We demonstrate two major approaches to testing for cointegration:
- The Engle–Granger two-step method
- The Johansen procedure</p>

<h3>How to use cointegration for a pairs-trading strategy</h3>

<p>Pairs-trading relies on a stationary, mean-reverting relationship between two asset prices. In other words, the ratio or difference between the two prices, also called the spread, may over time diverge but should ultimately return to the same level. Given such a pair, the strategy consists of going long (that is, purchasing) the under-performing asset because it would require a period of outperformance to close the gap. At the same time, one would short the asset that has moved away from the price anchor in the positive direction to fund the purchase.</p>

<p>In practice, given a universe of assets, a pairs-trading strategy will search for co-integrated pairs by running a statistical test on each pair. The key challenge here is to account for multiple testing biases, as outlined in <a href="../06_machine_learning_process">Chapter 6, Machine Learning Workflow</a>.</p>

<ul>
<li><a href="https://www.quantopian.com/lectures/introduction-to-pairs-trading">Introduction to Pairs Trading</a></li>
</ul>
