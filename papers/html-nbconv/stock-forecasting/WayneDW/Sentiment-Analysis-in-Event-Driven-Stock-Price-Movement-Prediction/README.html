<h1>Sentiment Analysis for Event-Driven Stock Prediction</h1>

<p>Use natural-language processing (NLP) to predict stock price movement based on Reuters News</p>

<h2>Website</h2>

<p>You are welcome to visit our website: <a href="http://goldenrocks.me/">GolenRocks.me</a>. The main purpose of this project is to build the connection between Bayesian DNN and stock price prediction based on News headline. </p>

<h2>Methodology</h2>

<ol>
<li><p>Data Collection and Preprocessing</p>

<p>1.1 crawl a ticker list to obtain the details of public companies</p>

<p>1.2 crawl news from Reuters using BeautifulSoup</p>

<p>1.3 crawl prices using urllib</p></li>
<li><p>Feature Engineering (Tokenization)</p>

<p>2.1 Unify word format: unify tense, singular &amp; plural, remove punctuations &amp; stop words</p>

<p>2.2 Implement one-hot encoding</p>

<p>2.3 Pad word sequence (essentially a matrix) to keep the same dimension</p></li>
<li><p>Train a set of Bayesian Convolutional Neural Networks using Stochastic Gradient Langevin Dynamics to obtain more robustness</p></li>
<li>Use thinning models to predict future news</li>
</ol>

<h2>Requirement</h2>

<ul>
<li>Python 3</li>
<li><a href="https://pytorch.org/">PyTorch > 0.4</a></li>
<li>numpy</li>
<li><a href="https://www.nltk.org/install.html">NLTK</a></li>
<li>Crawler tools
<ul>
<li>pip3 install lxml</li>
<li>pip3 install bs4</li>
<li>pip3 install urllib</li>
</ul></li>
</ul>

<h2>Usage</h2>

<p>Note: If you don't want to take time to crawl data and train the model, you can also directly go to step 4.</p>

<h3>1. Data collection</h3>

<h4>1.1 Download the ticker list from <a href="http://www.nasdaq.com/screening/companies-by-industry.aspx">NASDAQ</a></h4>

<p><code>bash
$ ./crawler/all_tickers.py 20  # keep the top e.g. 20% marketcap companies
</code></p>

<h4>1.2 Use BeautifulSoup to crawl news headlines from <a href="http://www.reuters.com/finance/stocks/overview?symbol=FB.O">Reuters</a></h4>

<p><em>Note: you may need over one month to fetch the news you want.</em></p>

<p>Suppose we find a piece of news about COO Lu Qi Resignation on May.18, 2018 at reuters.com</p>

<p><img src="./imgs/baidu.PNG" alt="" title="" /></p>

<p>We can use the following script to crawl it and format it to our local file</p>

<p><code>bash
$ ./crawler/reuters.py # we can relate the news with company and date, this is more precise than Bloomberg News
</code></p>

<p><img src="./imgs/111.png" alt="" title="" /></p>

<p>By brute-force iterating company tickers and dates, we can get the dataset with roughly 400,000 news in the end. Since a company may have multiple news in a single day, the current version will only use topStory news to train our models and ignore the others.</p>

<h4>1.3 Use urllib to crawl historical stock prices</h4>

<p>Improvement here, use normalized return [5] over S&amp;P 500 instead of return.</p>

<p><code>bash
$ ./crawler/yahoo_finance.py # generate raw data: stockPrices_raw.json, containing open, close, ..., adjClose
$ ./create_label.py # use raw price data to generate stockReturns.json
</code></p>

<h3>2. Feature engineering (Tokenization)</h3>

<p>Unify the word format, project word to a word vector, so every sentence results in a matrix.</p>

<p>Detail about unifying word format are: lower case, remove punctuation, get rid of stop words, unify tense and singular &amp; plural.</p>

<p><code>bash
$ ./tokenize_news.py
</code></p>

<h3>3. Train a Bayesian ConvNet to predict the stock price movement.</h3>

<p>Type the following to train a set of robust Bayesian models.
<code>bash
$ ./main.py -epochs 500 -static False
</code></p>

<h3>4. Prediction and analysis</h3>

<p>Let's show one example how the thinning models react to Baidu Lu Qi's resignation
```bash
$ ./main.py -predict "Top executive behind Baidu's artificial intelligence drive steps aside"</p>

<blockquote>
  <blockquote>
  <p>Sell
```
The prediction makes sense, let's find another one.</p>
</blockquote>

<p></blockquote></p>

<p><code>
Eli Lilly and Co (LLY.N)
FRI, JUN 1 2018
UPDATE 2-Lilly gets U.S. nod for arthritis drug, sets price well below rivals
* Drug priced at $25,000/year, 60 pct lower to AbbVie's Humira
</code></p>

<p>```bash
$ ./main.py -predict "UPDATE 2-Lilly gets U.S. nod for arthritis drug  sets price well below rivals"</p>

<blockquote>
  <blockquote>
  <p>Sell
```</p>
</blockquote>

<p></blockquote></p>

<p>Lowering down drug prices looks helpful to gain market share in the business, however, they didn't mention too much about the updates of technology, we are inclined to regard it as the virulent price competition, which does not help to the company earnings. Thus it is not a bad decision to sell Eli Lilly stocks.</p>

<p>Next, let's see what the buy options look like:</p>

<p><code>
Alphabet Inc (GOOG.O)
WED, MAY 30 2018
Google launches the second app in China, woos top smartphone market
* BEIJING Alphabet Inc's Google has launched a file managing tool in several Chinese app stores as it 
* looks for fresh inroads into the world's biggest smartphone market, where most of the internet 
* giant's top products remain banned.
</code></p>

<p>```bash
$ ./main.py -predict "Google launches the second app in China  woos top smartphone market"</p>

<blockquote>
  <blockquote>
  <p>Strong Buy
```</p>
</blockquote>

<p></blockquote></p>

<p>By now, you have basically understood how the models work, let's use backtesting to examine the performance on the news in the past two weeks.
```bash
$ ./main.py -eval True</p>

<blockquote>
  <blockquote>
  <p>Testing    - loss: 0.6761  acc: 58.07%(41.8/72.0) 83.50%(3.3/3.9) 100.00%(0.0/0.0) 0.00%(0.0/0.0) 
```
Note: the predictions are averaged, which explains why we have float numbers. From left to right, the predictions become more and more confident. 58% is actually much higher than my expectation, I believe when tested on a longer time horizon, the performance gets worse. However, as long as the predictions are better than random guesses (50%), you can't lose money betting on a favorable game (assume no trading cost and liquidity issue).</p>
</blockquote>

<p></blockquote></p>

<h3>5. Future works</h3>

<p>This is a very rough work. A better label should be based on the comparison of stock price changes between the company and the corresponding industry, instead of the S&amp;P 500, which is in spririt similar to hedging.</p>

<p>By <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1331573">Tim Loughran and Bill McDonald</a>, some words have strong indications of positive and negative effects in finance, e.g. company merger and acquisition. Therefore we need to dig into these words to find more information. In addition, detailed analysis and comparison in each industry are also useful.</p>

<p>Another simple but interesting example can be found in <a href="http://francescopochetti.com/scrapying-around-web/">Financial Sentiment Analysis part1</a>, <a href="http://francescopochetti.com/financial-blogs-sentiment-analysis-part-crawling-web/">part2</a>. </p>

<p>Since a comprehensive stopword list is quite helpful in improving the prediction power, you are very welcome to build a better stopword list and share it.</p>

<h2>References:</h2>

<ol>
<li>Yoon Kim, <a href="http://www.aclweb.org/anthology/D14-1181">Convolutional Neural Networks for Sentence Classification</a>, EMNLP, 2014</li>
<li>J Pennington, R Socher, CD Manning, <a href="http://www-nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation</a>, EMNLP, 2014</li>
<li>Max Welling, Yee Whye Teh, <a href="https://pdfs.semanticscholar.org/aeed/631d6a84100b5e9a021ec1914095c66de415.pdf">Bayesian Learning via Stochastic Gradient Langevin Dynamics</a>, ICML, 2011</li>
<li>Tim Loughran and Bill McDonald, 2011, “When is a Liability not a Liability?  Textual Analysis, Dictionaries, and 10-Ks,” Journal of Finance, 66:1, 35-65.</li>
<li>H Lee, etc, <a href="http://nlp.stanford.edu/pubs/lrec2014-stock.pdf">On the Importance of Text Analysis for Stock Price Prediction</a>, LREC, 2014</li>
<li>Xiao Ding, <a href="http://ijcai.org/Proceedings/15/Papers/329.pdf">Deep Learning for Event-Driven Stock Prediction</a>, IJCAI2015</li>
<li><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">IMPLEMENTING A CNN FOR TEXT CLASSIFICATION IN TENSORFLOW</a></li>
<li><a href="http://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/">Keras predict sentiment-movie-reviews using deep learning</a></li>
<li><a href="http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/">Keras sequence-classification-lstm-recurrent-neural-networks</a></li>
<li><a href="https://github.com/lazyprogrammer/machine_learning_examples/blob/master/nlp_class2/tfidf_tsne.py">tf-idf + t-sne</a></li>
<li><a href="https://github.com/dennybritz/cnn-text-classification-tf">Implementation of CNN in sequence classification</a></li>
<li><a href="http://textminingonline.com/getting-started-with-word2vec-and-glove-in-python">Getting Started with Word2Vec and GloVe in Python</a></li>
<li><a href="https://github.com/Shawn1993/cnn-text-classification-pytorch">PyTorch Implementation of Kim's Convolutional Neural Networks for Sentence Classification</a></li>
</ol>
